{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6324b439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/zipball/v0.6.0\" to C:\\Users\\parth/.cache\\torch\\hub\\v0.6.0.zip\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to C:\\Users\\parth/.cache\\torch\\hub\\checkpoints\\resnet18-5c106cde.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 44.7M/44.7M [00:06<00:00, 7.79MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ab2259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "#dowloand human-readable labels for Imagenet\n",
    "response = requests.get(\"https://git.io/JJkYN\")\n",
    "labels = response.text.split(\"\\n\")\n",
    "\n",
    "def predict(inp):\n",
    "    inp = transforms.ToTensor()(inp).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)\n",
    "        confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n",
    "    return confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71c77d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81aa5047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth/.cache\\torch\\hub\\pytorch_vision_v0.6.0\\torchvision\\transforms\\functional.py:74: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n"
     ]
    }
   ],
   "source": [
    "inti= gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=gr.Label(num_top_classes=3),\n",
    "    examples=[\"/content/lion.jpg\", \"/content/cheetah.jpg\"]).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53671c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
